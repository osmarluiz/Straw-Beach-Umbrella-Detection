{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "ROOT_DIR = 'F:/detectron2/'\n",
    "assert os.path.exists(ROOT_DIR)\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register datasets in COCO format\n",
    "\n",
    "register_coco_instances(1, 2, 3, 4)\n",
    "\n",
    "- First parameter (1): the name of the dataset (e.g., 'train', 'test', 'val')\n",
    "- Second parameter (2): Metadata, you can set it to '{}'\n",
    "- Third parameter (3): The path to the coco_instances.json file\n",
    "- Fourth parameter (4): The path to the images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register train data\n",
    "register_coco_instances(\"train\", {}, \n",
    "                        \"F:/0_tents/train/1x/coco_instances.json\", \n",
    "                        \"F:/0_tents/train/1x/amostras\")\n",
    "# register val data\n",
    "register_coco_instances(\"val\", {}, \n",
    "                        \"F:/0_tents/val/1x/coco_instances.json\", \n",
    "                        \"F:/0_tents/val/1x/amostras\")\n",
    "#register test data\n",
    "register_coco_instances(\"test\", {}, \n",
    "                        \"F:/0_tents/test/1x/coco_instances.json\", \n",
    "                        \"F:/0_tents/test/1x/amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "- We have to use a trainer in Detectron2\n",
    "\n",
    "- We can add new metrics here\n",
    "\n",
    "- The COCOEvaluator performs the standard COCO metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"result/Resnet_101\", exist_ok=True)\n",
    "        output_folder = \"result/Resnet_101\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "\n",
    "Take a look in the Detectron2 defaults.py file. There are many parameters we can change.\n",
    "\n",
    "This is just a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# load cfg\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Choose model\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = (\"val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "\n",
    "# Number of images per batch\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "\n",
    "# Learning Rate\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "\n",
    "# Number of epochs\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "\n",
    "# Steps per learning rate reduction\n",
    "#cfg.SOLVER.STEPS = (1000,)\n",
    "\n",
    "# How much learning rate will reduce\n",
    "#cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "# Number of proposals\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 320   # Default 512\n",
    "\n",
    "# Number of classes\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # number of classes (only beach straw umbrellas)\n",
    "\n",
    "# Load pre trained weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "\n",
    "# if you have a trained model, comment the line above and use this\n",
    "#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "\n",
    "# backbone freeze, since the images have different number of channels, i think it is best to train all layers\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 0\n",
    "\n",
    "# Number of epochs to evaluate model, the frequency of evaluation on the val set\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg) # This is another training option\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an evaluation on the val or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.evaluation import SemSegEvaluator\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"test\", cfg, False, output_dir=\"./output/\")\n",
    "test_loader = build_detection_test_loader(cfg, \"test\")\n",
    "inference_on_dataset(trainer.model, test_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "import imageio\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg) # this is the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'F:/0_tents/test/1x/amostras/img_1.tiff' # select path to evaluate image\n",
    "\n",
    "image = imageio.imread(img_path)\n",
    "print(image.shape)\n",
    "\n",
    "outputs = predictor(image)\n",
    "v = Visualizer(image[:,:,1:4]/5.5, metadata=test_metadata, scale=1) # I sliced the image since it should only show RGB for visualization (you can choose any other 3 channels)\n",
    "out = v.draw_instance_predictions(outputs['instances'].to('cpu'))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "plt.imshow(out.get_image()[:, :, ::-1])\n",
    "\n",
    "#plt.savefig('fig_43_original', dpi=400,  bbox_inches='tight', pad_inches=0) # saving the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs # take a look on how the predictions are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
